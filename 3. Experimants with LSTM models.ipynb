{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# преобразование строчек словарей в словарь\n",
    "import ast\n",
    "import json\n",
    "# преобразование адресов скринов в md5\n",
    "import hashlib\n",
    "# для текстов\n",
    "# import artm\n",
    "import os\n",
    "# для картинок\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import recurrent, BatchNormalization, Activation, Merge, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, Bidirectional\n",
    "# from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv('embeddings.csv', header=None)\n",
    "data = pd.read_table(\"df_export_all_new.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[(data['autobanned']==True), 'byHandModerationStatus'] = 'BAD_FOR_RECOMMENDER'\n",
    "data.loc[(data['tolokaModerationStatus']=='BAD_FOR_RECOMMENDER') & (data['byHandModerationStatus']!='OK'), 'byHandModerationStatus'] = 'BAD_FOR_RECOMMENDER'\n",
    "data.loc[(data['isSuper']==True) & (data['byHandModerationStatus']=='BAD_FOR_RECOMMENDER'), 'isSuper'] = False\n",
    "data['res'] = pd.Series(np.zeros(len(data)))\n",
    "data.loc[data.byHandModerationStatus=='OK', 'res'] = 3\n",
    "data.loc[data.isSuper==True, 'res'] = 2\n",
    "data.loc[data.byHandModerationStatus=='BAD_FOR_RECOMMENDER', 'res'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_dict = {}\n",
    "d_keys = list(ast.literal_eval(data.type_counts[0]).keys())\n",
    "for key in d_keys:\n",
    "    big_dict[key] = []\n",
    "for str_dict in data.type_counts:\n",
    "    curr_dict = ast.literal_eval(str_dict)\n",
    "    for key in d_keys:\n",
    "        big_dict[key].append(curr_dict[key])\n",
    "big_dict['text_num'] = big_dict['text']\n",
    "big_dict['text_title'] = big_dict['text-title']\n",
    "big_dict.pop('text', None)\n",
    "_ = big_dict.pop('text-title', None)\n",
    "text_type_features = pd.DataFrame(big_dict)\n",
    "data = pd.concat([data, text_type_features], axis=1)\n",
    "train_df = data[data.res!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8385"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lstm_train = np.load('X_lstm_train.npy')\n",
    "y_lstm_train = np.load('y_lstm_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8385, 12, 96)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lstm = np.zeros((max(train_df.index)+1, max(train_df.slidesCount), 96), dtype=np.float)\n",
    "y_lstm = np.zeros((max(train_df.index)+1, 3), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lstm[train_df.index] = X_lstm_train\n",
    "y_lstm[train_df.index] = y_lstm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_exp = pd.read_table('topic_probs_expanded.csv')\n",
    "topic_exp.index = train_df.index\n",
    "train_df = pd.concat([train_df, topic_exp], axis=1)\n",
    "train_df.loc[train_df.text.isnull(), topic_exp.columns] = 0.0\n",
    "tmc = topic_exp.columns[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_LDA_medians = []\n",
    "for i in range(1,4):\n",
    "    topic_LDA_medians.append(np.median(df_train.loc[y_train==i, tmc], axis=0))\n",
    "topic_LDA_means = []\n",
    "for i in range(1,4):\n",
    "    topic_LDA_means.append(np.mean(df_train.loc[y_train==i, tmc], axis=0))\n",
    "topic_LDA_75_quantile = []\n",
    "for i in range(1,4):\n",
    "    topic_LDA_75_quantile.append(np.percentile(df_train.loc[y_train==i, tmc], 75, axis=0))\n",
    "topic_LDA_25_quantile = []\n",
    "for i in range(1,4):\n",
    "    topic_LDA_25_quantile.append(np.percentile(df_train.loc[y_train==i, tmc], 25, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.res = train_df.res.astype(int)\n",
    "from scipy.spatial.distance import cosine\n",
    "def cos_dist_from_median(val):\n",
    "    res = cosine(topic_LDA_medians[val.res-1], val[tmc.tolist()].tolist())\n",
    "    if (np.isnan(res)):\n",
    "        return -1\n",
    "    return res\n",
    "\n",
    "def cos_dist_from_mean(val):\n",
    "    res = cosine(topic_LDA_means[val.res-1], val[tmc.tolist()].tolist())\n",
    "    if (np.isnan(res)):\n",
    "        return -1\n",
    "    return res\n",
    "\n",
    "def cos_dist_from_75_per(val):\n",
    "    res = cosine(topic_LDA_75_quantile[val.res-1], val[tmc.tolist()].tolist())\n",
    "    if (np.isnan(res)):\n",
    "        return -1\n",
    "    return res\n",
    "\n",
    "def cos_dist_from_25_per(val):\n",
    "    res = cosine(topic_LDA_25_quantile[val.res-1], val[tmc.tolist()].tolist())\n",
    "    if (np.isnan(res)):\n",
    "        return -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "cos_median_distances = train_df.apply(cos_dist_from_median, axis=1)\n",
    "cos_mean_distances = train_df.apply(cos_dist_from_mean, axis=1)\n",
    "cos_75_percentile_distaces = train_df.apply(cos_dist_from_75_per, axis=1)\n",
    "cos_25_percentile_distaces = train_df.apply(cos_dist_from_25_per, axis=1)\n",
    "train_df['cos_median_distances2'] = cos_median_distances\n",
    "train_df['cos_mean_distances2'] = cos_mean_distances\n",
    "train_df['cos_75_percentile_distances'] = cos_75_percentile_distaces\n",
    "train_df['cos_25_percentile_distances'] = cos_25_percentile_distaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df.res.astype(int)\n",
    "df = train_df.drop('res', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = ['slidesCount', \n",
    "                'publisherFavouritesCount', 'publisherMonetizationAvailable',\n",
    "               'publisherPublications', 'publisherQualityNumeric',\n",
    "               'image', 'text_num', 'text_title', 'url', 'video',\n",
    "                              'topic_0', 'topic_1', 'topic_2',\n",
    "       'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8',\n",
    "       'topic_9', 'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14',\n",
    "       'top_theme', 'cos_median_distances2', 'cos_mean_distances2', 'cos_75_percentile_distances', 'cos_25_percentile_distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lstm_train = X_lstm[df_train.index]\n",
    "y_lstm_train = y_lstm[df_train.index]\n",
    "X_lstm_valid = X_lstm[df_valid.index]\n",
    "y_lstm_valid = y_lstm[df_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_y_lstm = np.zeros((len(y_lstm), 2), dtype=np.float)\n",
    "for i in range(len(y_lstm_train)):\n",
    "    if ((y_lstm_train[i][0]==1.0)):\n",
    "        binary_y_lstm[i][0] = 1.0\n",
    "    else:\n",
    "        binary_y_lstm[i][1] = 1.0\n",
    "binary_y_lstm_train = binary_y_lstm[df_train.index]\n",
    "binary_y_lstm_valid = binary_y_lstm[df_valid.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = ss.fit_transform(df_train.loc[:, all_features])\n",
    "df_valid = ss.transform(df_valid.loc[:, all_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(epsilon=1e-06, momentum=0.9, weights=None)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6708 samples, validate on 1677 samples\n",
      "Epoch 1/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.9062 - acc: 0.6122Epoch 00001: val_acc improved from -inf to 0.70841, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 24s 4ms/step - loss: 0.9059 - acc: 0.6124 - val_loss: 0.7307 - val_acc: 0.7084\n",
      "Epoch 2/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6809 - acc: 0.7097Epoch 00002: val_acc improved from 0.70841 to 0.74597, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 895us/step - loss: 0.6818 - acc: 0.7095 - val_loss: 0.6352 - val_acc: 0.7460\n",
      "Epoch 3/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6180 - acc: 0.7391Epoch 00003: val_acc improved from 0.74597 to 0.75730, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 889us/step - loss: 0.6182 - acc: 0.7388 - val_loss: 0.6070 - val_acc: 0.7573\n",
      "Epoch 4/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5908 - acc: 0.7442Epoch 00004: val_acc improved from 0.75730 to 0.76863, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 924us/step - loss: 0.5899 - acc: 0.7451 - val_loss: 0.5862 - val_acc: 0.7686\n",
      "Epoch 5/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.7660Epoch 00005: val_acc improved from 0.76863 to 0.78354, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 921us/step - loss: 0.5538 - acc: 0.7660 - val_loss: 0.5582 - val_acc: 0.7835\n",
      "Epoch 6/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.8005Epoch 00006: val_acc improved from 0.78354 to 0.79905, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 924us/step - loss: 0.4840 - acc: 0.8007 - val_loss: 0.4934 - val_acc: 0.7990\n",
      "Epoch 7/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8299Epoch 00007: val_acc improved from 0.79905 to 0.82528, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 7s 983us/step - loss: 0.4205 - acc: 0.8295 - val_loss: 0.4486 - val_acc: 0.8253\n",
      "Epoch 8/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8516Epoch 00008: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 883us/step - loss: 0.3794 - acc: 0.8515 - val_loss: 0.4263 - val_acc: 0.8140\n",
      "Epoch 9/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8564Epoch 00009: val_acc improved from 0.82528 to 0.86285, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 907us/step - loss: 0.3612 - acc: 0.8561 - val_loss: 0.3486 - val_acc: 0.8629\n",
      "Epoch 10/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.8719Epoch 00010: val_acc improved from 0.86285 to 0.86881, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 908us/step - loss: 0.3172 - acc: 0.8722 - val_loss: 0.3453 - val_acc: 0.8688\n",
      "Epoch 11/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8816Epoch 00011: val_acc improved from 0.86881 to 0.87239, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 884us/step - loss: 0.2984 - acc: 0.8816 - val_loss: 0.3194 - val_acc: 0.8724\n",
      "Epoch 12/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.8958Epoch 00012: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 878us/step - loss: 0.2740 - acc: 0.8955 - val_loss: 0.3623 - val_acc: 0.8682\n",
      "Epoch 13/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.2579 - acc: 0.9015Epoch 00013: val_acc improved from 0.87239 to 0.89803, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 913us/step - loss: 0.2582 - acc: 0.9010 - val_loss: 0.2786 - val_acc: 0.8980\n",
      "Epoch 14/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.2483 - acc: 0.9045Epoch 00014: val_acc improved from 0.89803 to 0.89922, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 896us/step - loss: 0.2483 - acc: 0.9044 - val_loss: 0.2794 - val_acc: 0.8992\n",
      "Epoch 15/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9157Epoch 00015: val_acc improved from 0.89922 to 0.90817, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 904us/step - loss: 0.2196 - acc: 0.9153 - val_loss: 0.2614 - val_acc: 0.9082\n",
      "Epoch 16/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9134Epoch 00016: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 894us/step - loss: 0.2293 - acc: 0.9135 - val_loss: 0.2985 - val_acc: 0.9004\n",
      "Epoch 17/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.2348 - acc: 0.9079Epoch 00017: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 876us/step - loss: 0.2349 - acc: 0.9077 - val_loss: 0.2718 - val_acc: 0.9052\n",
      "Epoch 18/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9270Epoch 00018: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 878us/step - loss: 0.1962 - acc: 0.9267 - val_loss: 0.2826 - val_acc: 0.8980\n",
      "Epoch 19/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9294Epoch 00019: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 911us/step - loss: 0.1918 - acc: 0.9295 - val_loss: 0.2497 - val_acc: 0.9064\n",
      "Epoch 20/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9416Epoch 00020: val_acc improved from 0.90817 to 0.91413, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 946us/step - loss: 0.1621 - acc: 0.9416 - val_loss: 0.2703 - val_acc: 0.9141\n",
      "Epoch 21/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9390Epoch 00021: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 905us/step - loss: 0.1702 - acc: 0.9387 - val_loss: 0.2692 - val_acc: 0.9028\n",
      "Epoch 22/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9401Epoch 00022: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 889us/step - loss: 0.1612 - acc: 0.9402 - val_loss: 0.2743 - val_acc: 0.9123\n",
      "Epoch 23/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9474Epoch 00023: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 903us/step - loss: 0.1435 - acc: 0.9474 - val_loss: 0.2855 - val_acc: 0.9070\n",
      "Epoch 24/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9452Epoch 00024: val_acc improved from 0.91413 to 0.92188, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 920us/step - loss: 0.1473 - acc: 0.9451 - val_loss: 0.2622 - val_acc: 0.9219\n",
      "Epoch 25/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9505Epoch 00025: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 913us/step - loss: 0.1401 - acc: 0.9507 - val_loss: 0.2575 - val_acc: 0.9165\n",
      "Epoch 26/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9517Epoch 00026: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 869us/step - loss: 0.1364 - acc: 0.9513 - val_loss: 0.2877 - val_acc: 0.9141\n",
      "Epoch 27/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9566Epoch 00027: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 879us/step - loss: 0.1257 - acc: 0.9566 - val_loss: 0.2984 - val_acc: 0.9141\n",
      "Epoch 28/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9544Epoch 00028: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 888us/step - loss: 0.1203 - acc: 0.9547 - val_loss: 0.2862 - val_acc: 0.9129\n",
      "Epoch 29/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9572Epoch 00029: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 898us/step - loss: 0.1203 - acc: 0.9571 - val_loss: 0.2880 - val_acc: 0.9123\n",
      "Epoch 30/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9618Epoch 00030: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 889us/step - loss: 0.1098 - acc: 0.9609 - val_loss: 0.2697 - val_acc: 0.9129\n",
      "Epoch 31/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9536Epoch 00031: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 879us/step - loss: 0.1338 - acc: 0.9535 - val_loss: 0.2685 - val_acc: 0.9171\n",
      "Epoch 32/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9665Epoch 00032: val_acc improved from 0.92188 to 0.92308, saving model to ./slides_lstm10.model\n",
      "6708/6708 [==============================] - 6s 901us/step - loss: 0.0955 - acc: 0.9662 - val_loss: 0.2832 - val_acc: 0.9231\n",
      "Epoch 33/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9700Epoch 00033: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 893us/step - loss: 0.0954 - acc: 0.9700 - val_loss: 0.2833 - val_acc: 0.9201\n",
      "Epoch 34/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9692Epoch 00034: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 922us/step - loss: 0.0861 - acc: 0.9691 - val_loss: 0.3057 - val_acc: 0.9189\n",
      "Epoch 35/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9721Epoch 00035: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 900us/step - loss: 0.0781 - acc: 0.9720 - val_loss: 0.3005 - val_acc: 0.9183\n",
      "Epoch 36/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9680Epoch 00036: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 921us/step - loss: 0.0890 - acc: 0.9681 - val_loss: 0.2928 - val_acc: 0.9183\n",
      "Epoch 37/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9734Epoch 00037: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 893us/step - loss: 0.0773 - acc: 0.9732 - val_loss: 0.3061 - val_acc: 0.9141\n",
      "Epoch 38/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9737Epoch 00038: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 901us/step - loss: 0.0777 - acc: 0.9738 - val_loss: 0.3035 - val_acc: 0.9213\n",
      "Epoch 39/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9792Epoch 00039: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 905us/step - loss: 0.0676 - acc: 0.9790 - val_loss: 0.3472 - val_acc: 0.9153\n",
      "Epoch 40/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9716Epoch 00040: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 912us/step - loss: 0.0844 - acc: 0.9717 - val_loss: 0.3095 - val_acc: 0.9165\n",
      "Epoch 41/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9801Epoch 00041: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 888us/step - loss: 0.0643 - acc: 0.9799 - val_loss: 0.3496 - val_acc: 0.9141\n",
      "Epoch 42/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9465Epoch 00042: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 881us/step - loss: 0.1589 - acc: 0.9466 - val_loss: 0.3210 - val_acc: 0.9123\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "i = 10\n",
    "lstm_input = Input(shape=(max(train_df.slidesCount), 96,))\n",
    "lstm_model = Bidirectional(LSTM(HIDDEN_SIZE, recurrent_dropout=0.05, dropout=0.05))(lstm_input)\n",
    "extra_input = Input(shape=(len(all_features),))\n",
    "merged = concatenate([lstm_model, extra_input])\n",
    "prev_layer = merged\n",
    "for size in range(i):\n",
    "    lstm_dense = Dense(int(HIDDEN_SIZE/(i+1)), activation='elu')(prev_layer)\n",
    "    lstm_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_dense)\n",
    "    prev_layer = lstm_bn\n",
    "model_dense = Dense(3, activation='softmax')(prev_layer)\n",
    "model = Model(inputs=[lstm_input, extra_input], outputs=model_dense)\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm'+str(i)+'.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit([ X_lstm_train, df_train],  y_lstm_train, validation_data=([X_lstm_valid, df_valid], y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )\n",
    "\n",
    "model.load_weights(os.path.join('./','slides_lstm'+str(i)+'.model'))\n",
    "probs = model.predict([X_lstm_valid, df_valid])\n",
    "#     y_pred = []\n",
    "#     for prob in probs:\n",
    "#         y_pred.append(np.argmax(prob)+1)\n",
    "#     with open('res_with_themes_2.txt', 'a') as f:\n",
    "#         f.write(str(i)+'\\n')\n",
    "#         f.write(str(+'\\n')\n",
    "#         f.write(str(classification_report(y_valid, y_pred))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92486583184257598"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)\n",
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bidirection LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6708 samples, validate on 1677 samples\n",
      "Epoch 1/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.9584 - acc: 0.5704Epoch 00001: val_acc improved from -inf to 0.68336, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 13s 2ms/step - loss: 0.9583 - acc: 0.5705 - val_loss: 0.7708 - val_acc: 0.6834\n",
      "Epoch 2/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.7344 - acc: 0.7005Epoch 00002: val_acc improved from 0.68336 to 0.71199, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.7354 - acc: 0.6999 - val_loss: 0.7054 - val_acc: 0.7120\n",
      "Epoch 3/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.7056Epoch 00003: val_acc improved from 0.71199 to 0.71735, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6941 - acc: 0.7056 - val_loss: 0.6799 - val_acc: 0.7174\n",
      "Epoch 4/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6786 - acc: 0.7110Epoch 00004: val_acc improved from 0.71735 to 0.72987, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6789 - acc: 0.7106 - val_loss: 0.6647 - val_acc: 0.7299\n",
      "Epoch 5/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6725 - acc: 0.7081Epoch 00005: val_acc did not improve\n",
      "6708/6708 [==============================] - 7s 1ms/step - loss: 0.6726 - acc: 0.7080 - val_loss: 0.6779 - val_acc: 0.7203\n",
      "Epoch 6/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6693 - acc: 0.7119Epoch 00006: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6678 - acc: 0.7123 - val_loss: 0.6644 - val_acc: 0.7287\n",
      "Epoch 7/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6697 - acc: 0.7146Epoch 00007: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6697 - acc: 0.7145 - val_loss: 0.6682 - val_acc: 0.7233\n",
      "Epoch 8/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6622 - acc: 0.7178Epoch 00008: val_acc improved from 0.72987 to 0.73643, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6625 - acc: 0.7178 - val_loss: 0.6616 - val_acc: 0.7364\n",
      "Epoch 9/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6594 - acc: 0.7159Epoch 00009: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6588 - acc: 0.7166 - val_loss: 0.6640 - val_acc: 0.7257\n",
      "Epoch 10/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6567 - acc: 0.7179Epoch 00010: val_acc did not improve\n",
      "6708/6708 [==============================] - 7s 1ms/step - loss: 0.6567 - acc: 0.7177 - val_loss: 0.6552 - val_acc: 0.7340\n",
      "Epoch 11/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6561 - acc: 0.7199Epoch 00011: val_acc improved from 0.73643 to 0.73942, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6568 - acc: 0.7196 - val_loss: 0.6580 - val_acc: 0.7394\n",
      "Epoch 12/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.7277Epoch 00012: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6473 - acc: 0.7273 - val_loss: 0.6552 - val_acc: 0.7281\n",
      "Epoch 13/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6391 - acc: 0.7306Epoch 00013: val_acc did not improve\n",
      "6708/6708 [==============================] - 7s 1ms/step - loss: 0.6396 - acc: 0.7305 - val_loss: 0.6513 - val_acc: 0.7382\n",
      "Epoch 14/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6442 - acc: 0.7303Epoch 00014: val_acc improved from 0.73942 to 0.74955, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 9s 1ms/step - loss: 0.6443 - acc: 0.7300 - val_loss: 0.6440 - val_acc: 0.7496\n",
      "Epoch 15/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6360 - acc: 0.7335Epoch 00015: val_acc improved from 0.74955 to 0.75253, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6368 - acc: 0.7335 - val_loss: 0.6453 - val_acc: 0.7525\n",
      "Epoch 16/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6354 - acc: 0.7324Epoch 00016: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6357 - acc: 0.7326 - val_loss: 0.6459 - val_acc: 0.7507\n",
      "Epoch 17/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6294 - acc: 0.7325Epoch 00017: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6280 - acc: 0.7333 - val_loss: 0.6446 - val_acc: 0.7513\n",
      "Epoch 18/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.7355Epoch 00018: val_acc did not improve\n",
      "6708/6708 [==============================] - 7s 1ms/step - loss: 0.6299 - acc: 0.7354 - val_loss: 0.6352 - val_acc: 0.7490\n",
      "Epoch 19/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.7373Epoch 00019: val_acc improved from 0.75253 to 0.75552, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6217 - acc: 0.7375 - val_loss: 0.6324 - val_acc: 0.7555\n",
      "Epoch 20/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.7352Epoch 00020: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6252 - acc: 0.7339 - val_loss: 0.6435 - val_acc: 0.7537\n",
      "Epoch 21/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6210 - acc: 0.7443Epoch 00021: val_acc improved from 0.75552 to 0.75611, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6218 - acc: 0.7436 - val_loss: 0.6365 - val_acc: 0.7561\n",
      "Epoch 22/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6148 - acc: 0.7434Epoch 00022: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6147 - acc: 0.7433 - val_loss: 0.6300 - val_acc: 0.7513\n",
      "Epoch 23/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.7457Epoch 00023: val_acc improved from 0.75611 to 0.75611, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6124 - acc: 0.7455 - val_loss: 0.6267 - val_acc: 0.7561\n",
      "Epoch 24/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.7450Epoch 00024: val_acc improved from 0.75611 to 0.75969, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6133 - acc: 0.7457 - val_loss: 0.6247 - val_acc: 0.7597\n",
      "Epoch 25/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6064 - acc: 0.7503Epoch 00025: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6067 - acc: 0.7501 - val_loss: 0.6266 - val_acc: 0.7537\n",
      "Epoch 26/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.7463Epoch 00026: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.6043 - acc: 0.7460 - val_loss: 0.6270 - val_acc: 0.7460\n",
      "Epoch 27/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.7534Epoch 00027: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5964 - acc: 0.7527 - val_loss: 0.6256 - val_acc: 0.7555\n",
      "Epoch 28/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5973 - acc: 0.7534Epoch 00028: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5975 - acc: 0.7534 - val_loss: 0.6286 - val_acc: 0.7460\n",
      "Epoch 29/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5867 - acc: 0.7578Epoch 00029: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5870 - acc: 0.7576 - val_loss: 0.6250 - val_acc: 0.7484\n",
      "Epoch 30/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.7584Epoch 00030: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5820 - acc: 0.7583 - val_loss: 0.6286 - val_acc: 0.7555\n",
      "Epoch 31/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5838 - acc: 0.7544Epoch 00031: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5837 - acc: 0.7549 - val_loss: 0.6200 - val_acc: 0.7549\n",
      "Epoch 32/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5802 - acc: 0.7617Epoch 00032: val_acc did not improve\n",
      "6708/6708 [==============================] - 9s 1ms/step - loss: 0.5797 - acc: 0.7616 - val_loss: 0.6137 - val_acc: 0.7472\n",
      "Epoch 33/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7600Epoch 00033: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5744 - acc: 0.7600 - val_loss: 0.6228 - val_acc: 0.7472\n",
      "Epoch 34/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.7647Epoch 00034: val_acc did not improve\n",
      "6708/6708 [==============================] - 8s 1ms/step - loss: 0.5676 - acc: 0.7645 - val_loss: 0.6273 - val_acc: 0.7466\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "lstm_input = Input(shape=(max(train_df.slidesCount), 96,))\n",
    "lstm_model = Bidirectional(LSTM(HIDDEN_SIZE, recurrent_dropout=0.05, dropout=0.05))(lstm_input)\n",
    "lstm_first_dense = Dense(int(HIDDEN_SIZE), activation='elu')(lstm_model)\n",
    "lstm_first_dropout = Dropout(0.1)(lstm_first_dense)\n",
    "lstm_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_first_dropout)\n",
    "lstm_second_dense = Dense(int(HIDDEN_SIZE), activation='elu')(lstm_first_bn)\n",
    "lstm_second_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_second_dense)\n",
    "lstm_third_dense = Dense(int(HIDDEN_SIZE), activation='elu')(lstm_second_bn)\n",
    "lstm_third_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_third_dense)\n",
    "lstm_classify_dense = Dense(3, activation='softmax')(lstm_third_bn)\n",
    "extra_input = Input(shape=(len(all_features),))\n",
    "# extra_dense = Dense(len(all_features), activation='linear')(extra_input)\n",
    "merged = concatenate([lstm_classify_dense, extra_input])\n",
    "model_first_dense = Dense(7, activation='elu')(merged)\n",
    "moden_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(model_first_dense)\n",
    "model_dense = Dense(3, activation='softmax')(moden_first_bn)\n",
    "model = Model(inputs=[lstm_input, extra_input], outputs=model_dense)\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit([ X_lstm_train, df_train],  y_lstm_train, validation_data=([X_lstm_valid, df_valid], y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "# print(df_train.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6708 samples, validate on 1677 samples\n",
      "Epoch 1/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.9328 - acc: 0.5774Epoch 00001: val_acc improved from -inf to 0.72451, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 7s 1ms/step - loss: 0.9317 - acc: 0.5784 - val_loss: 0.7469 - val_acc: 0.7245\n",
      "Epoch 2/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.7210 - acc: 0.7024Epoch 00002: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 800us/step - loss: 0.7212 - acc: 0.7024 - val_loss: 0.6929 - val_acc: 0.7209\n",
      "Epoch 3/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6756 - acc: 0.7163Epoch 00003: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 813us/step - loss: 0.6758 - acc: 0.7162 - val_loss: 0.7021 - val_acc: 0.7001\n",
      "Epoch 4/100\n",
      "6600/6708 [============================>.] - ETA: 0s - loss: 0.6500 - acc: 0.7170Epoch 00004: val_acc improved from 0.72451 to 0.73465, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 5s 809us/step - loss: 0.6490 - acc: 0.7182 - val_loss: 0.6774 - val_acc: 0.7346\n",
      "Epoch 5/100\n",
      "6600/6708 [============================>.] - ETA: 0s - loss: 0.6347 - acc: 0.7294Epoch 00005: val_acc improved from 0.73465 to 0.73763, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 5s 747us/step - loss: 0.6363 - acc: 0.7291 - val_loss: 0.6369 - val_acc: 0.7376\n",
      "Epoch 6/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.6282 - acc: 0.7314Epoch 00006: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 814us/step - loss: 0.6293 - acc: 0.7311 - val_loss: 0.6344 - val_acc: 0.7305\n",
      "Epoch 7/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6242 - acc: 0.7316Epoch 00007: val_acc improved from 0.73763 to 0.74001, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 6s 823us/step - loss: 0.6242 - acc: 0.7317 - val_loss: 0.6309 - val_acc: 0.7400\n",
      "Epoch 8/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.6102 - acc: 0.7419Epoch 00008: val_acc improved from 0.74001 to 0.75373, saving model to ./slides_lstm.model\n",
      "6708/6708 [==============================] - 5s 816us/step - loss: 0.6104 - acc: 0.7418 - val_loss: 0.6138 - val_acc: 0.7537\n",
      "Epoch 9/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5947 - acc: 0.7489Epoch 00009: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 736us/step - loss: 0.5932 - acc: 0.7497 - val_loss: 0.6266 - val_acc: 0.7472\n",
      "Epoch 10/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5871 - acc: 0.7530Epoch 00010: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 822us/step - loss: 0.5874 - acc: 0.7528 - val_loss: 0.6121 - val_acc: 0.7478\n",
      "Epoch 11/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5794 - acc: 0.7588Epoch 00011: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 800us/step - loss: 0.5785 - acc: 0.7595 - val_loss: 0.6161 - val_acc: 0.7388\n",
      "Epoch 12/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7635Epoch 00012: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 794us/step - loss: 0.5649 - acc: 0.7631 - val_loss: 0.6280 - val_acc: 0.7454\n",
      "Epoch 13/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5594 - acc: 0.7663Epoch 00013: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 760us/step - loss: 0.5600 - acc: 0.7658 - val_loss: 0.6295 - val_acc: 0.7340\n",
      "Epoch 14/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.7713Epoch 00014: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 826us/step - loss: 0.5550 - acc: 0.7718 - val_loss: 0.6347 - val_acc: 0.7376\n",
      "Epoch 15/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5285 - acc: 0.7854Epoch 00015: val_acc did not improve\n",
      "6708/6708 [==============================] - 6s 827us/step - loss: 0.5315 - acc: 0.7847 - val_loss: 0.6110 - val_acc: 0.7513\n",
      "Epoch 16/100\n",
      "6700/6708 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.7918Epoch 00016: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 765us/step - loss: 0.5218 - acc: 0.7920 - val_loss: 0.6223 - val_acc: 0.7478\n",
      "Epoch 17/100\n",
      "6650/6708 [============================>.] - ETA: 0s - loss: 0.5047 - acc: 0.7944Epoch 00017: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 752us/step - loss: 0.5035 - acc: 0.7949 - val_loss: 0.6236 - val_acc: 0.7496\n",
      "Epoch 18/100\n",
      "6600/6708 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.8006Epoch 00018: val_acc did not improve\n",
      "6708/6708 [==============================] - 5s 815us/step - loss: 0.4887 - acc: 0.8014 - val_loss: 0.6381 - val_acc: 0.7400\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "lstm_input = Input(shape=(max(train_df.slidesCount), 96,))\n",
    "lstm_model = LSTM(HIDDEN_SIZE, recurrent_dropout=0.05, dropout=0.05)(lstm_input)\n",
    "lstm_first_dense = Dense(int(HIDDEN_SIZE/4), activation='elu')(lstm_model)\n",
    "lstm_first_dropout = Dropout(0.1)(lstm_first_dense)\n",
    "lstm_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_first_dropout)\n",
    "lstm_second_dense = Dense(int(HIDDEN_SIZE/5), activation='elu')(lstm_first_bn)\n",
    "lstm_second_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_second_dense)\n",
    "lstm_third_dense = Dense(int(HIDDEN_SIZE/6), activation='elu')(lstm_second_bn)\n",
    "lstm_third_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_third_dense)\n",
    "lstm_classify_dense = Dense(3, activation='softmax')(lstm_third_bn)\n",
    "extra_input = Input(shape=(len(all_features),))\n",
    "# extra_dense = Dense(len(all_features), activation='linear')(extra_input)\n",
    "merged = concatenate([lstm_classify_dense, extra_input])\n",
    "model_first_dense = Dense(7, activation='elu')(merged)\n",
    "moden_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(model_first_dense)\n",
    "model_dense = Dense(3, activation='softmax')(moden_first_bn)\n",
    "model = Model(inputs=[lstm_input, extra_input], outputs=model_dense)\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit([ X_lstm_train, df_train],  y_lstm_train, validation_data=([X_lstm_valid, df_valid], y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('./','slides_lstm.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict([X_lstm_valid, df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76147883124627314"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.47      0.57       204\n",
      "          2       0.63      0.41      0.50       359\n",
      "          3       0.76      0.90      0.83      1114\n",
      "\n",
      "avg / total       0.73      0.74      0.72      1677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12028 samples, validate on 1337 samples\n",
      "Epoch 1/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.8833Epoch 00001: val_acc improved from -inf to 0.89940, saving model to ./slides_lstm.model\n",
      "12028/12028 [==============================] - 10s 842us/step - loss: 0.3470 - acc: 0.8833 - val_loss: 0.3039 - val_acc: 0.8994\n",
      "Epoch 2/100\n",
      "11940/12028 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.8855Epoch 00002: val_acc improved from 0.89940 to 0.90090, saving model to ./slides_lstm.model\n",
      "12028/12028 [==============================] - 7s 546us/step - loss: 0.3338 - acc: 0.8849 - val_loss: 0.3041 - val_acc: 0.9009\n",
      "Epoch 3/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8865Epoch 00003: val_acc improved from 0.90090 to 0.90127, saving model to ./slides_lstm.model\n",
      "12028/12028 [==============================] - 7s 541us/step - loss: 0.3311 - acc: 0.8867 - val_loss: 0.3023 - val_acc: 0.9013\n",
      "Epoch 4/100\n",
      "11910/12028 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.8871Epoch 00004: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 534us/step - loss: 0.3265 - acc: 0.8872 - val_loss: 0.3000 - val_acc: 0.9009\n",
      "Epoch 5/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.8879Epoch 00005: val_acc improved from 0.90127 to 0.90277, saving model to ./slides_lstm.model\n",
      "12028/12028 [==============================] - 6s 535us/step - loss: 0.3229 - acc: 0.8877 - val_loss: 0.3023 - val_acc: 0.9028\n",
      "Epoch 6/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.8893Epoch 00006: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 529us/step - loss: 0.3155 - acc: 0.8893 - val_loss: 0.3035 - val_acc: 0.8998\n",
      "Epoch 7/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.8923Epoch 00007: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 535us/step - loss: 0.3087 - acc: 0.8923 - val_loss: 0.3046 - val_acc: 0.8998\n",
      "Epoch 8/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.8939Epoch 00008: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 532us/step - loss: 0.3005 - acc: 0.8942 - val_loss: 0.3053 - val_acc: 0.9016\n",
      "Epoch 9/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.8951Epoch 00009: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 535us/step - loss: 0.2913 - acc: 0.8953 - val_loss: 0.3127 - val_acc: 0.8957\n",
      "Epoch 10/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.8949Epoch 00010: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 530us/step - loss: 0.2854 - acc: 0.8952 - val_loss: 0.3204 - val_acc: 0.8983\n",
      "Epoch 11/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.8985Epoch 00011: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 534us/step - loss: 0.2741 - acc: 0.8986 - val_loss: 0.3373 - val_acc: 0.9016\n",
      "Epoch 12/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9012Epoch 00012: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 530us/step - loss: 0.2615 - acc: 0.9012 - val_loss: 0.3666 - val_acc: 0.8901\n",
      "Epoch 13/100\n",
      "11970/12028 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9044Epoch 00013: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 540us/step - loss: 0.2523 - acc: 0.9043 - val_loss: 0.3498 - val_acc: 0.8901\n",
      "Epoch 14/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9085Epoch 00014: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 530us/step - loss: 0.2426 - acc: 0.9085 - val_loss: 0.3666 - val_acc: 0.8852\n",
      "Epoch 15/100\n",
      "12000/12028 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9104Epoch 00015: val_acc did not improve\n",
      "12028/12028 [==============================] - 6s 530us/step - loss: 0.2301 - acc: 0.9105 - val_loss: 0.3967 - val_acc: 0.8837\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "HIDDEN_SIZE = 200\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', input_shape=(max(train_df.slidesCount), 96), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(recurrent.LSTM(HIDDEN_SIZE,  recurrent_dropout=0.1, dropout=0.2))\n",
    "# model.add( Dense( int(HIDDEN_SIZE/5), activation='relu' ))\n",
    "model.add( Dropout(0.1) )\n",
    "model.add( Dense( 2, activation='sigmoid' ) )\n",
    "opt = keras.optimizers.Nadam(lr=0.002, epsilon=1e-09)\n",
    "model.compile( loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit( X_lstm_train, binary_y_lstm_train, validation_data=(X_lstm_valid, binary_y_lstm_valid),\n",
    "                    batch_size=30, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_other_valid = []\n",
    "for y_val in y_valid:\n",
    "    if (y_val==1.0):\n",
    "        y_other_valid.append(0)\n",
    "    else:\n",
    "        y_other_valid.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        96\n",
      "          1       0.93      0.98      0.95      1241\n",
      "\n",
      "avg / total       0.86      0.91      0.88      1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs_bad = model.predict_proba(X_lstm_valid)\n",
    "y_pred_bad = []\n",
    "for prob in probs_bad:\n",
    "    y_pred_bad.append(np.argmax(prob))\n",
    "print(classification_report(y_other_valid, y_pred_bad))\n",
    "# 0 - это плохо; 1 - остальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_other_valid = []\n",
    "for y_val in y_valid:\n",
    "    if (y_val==2.0):\n",
    "        y_other_valid.append(0)\n",
    "    else:\n",
    "        y_other_valid.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.15      0.15      0.15       179\n",
      "          1       0.77      0.78      0.77       660\n",
      "\n",
      "avg / total       0.64      0.64      0.64       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs_super = model.predict_proba(X_lstm_valid)\n",
    "y_pred_super = []\n",
    "for prob in probs_super:\n",
    "    y_pred_super.append(np.argmax(prob))\n",
    "print(classification_report(y_other_valid, y_pred_super))\n",
    "# 0 - это супер; 1 - остальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12696, 12, 96)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12696, 10)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \"\"\"\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  import sys\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  if __name__ == '__main__':\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12696 samples, validate on 669 samples\n",
      "Epoch 1/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.7719 - acc: 0.7206Epoch 00001: val_acc improved from -inf to 0.80120, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 15s 1ms/step - loss: 0.7699 - acc: 0.7213 - val_loss: 0.5341 - val_acc: 0.8012\n",
      "Epoch 2/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.5386 - acc: 0.7932Epoch 00002: val_acc improved from 0.80120 to 0.81016, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 487us/step - loss: 0.5389 - acc: 0.7932 - val_loss: 0.4940 - val_acc: 0.8102\n",
      "Epoch 3/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.5225 - acc: 0.7977Epoch 00003: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 481us/step - loss: 0.5227 - acc: 0.7976 - val_loss: 0.4786 - val_acc: 0.8072\n",
      "Epoch 4/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.5128 - acc: 0.8007Epoch 00004: val_acc improved from 0.81016 to 0.81614, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 489us/step - loss: 0.5124 - acc: 0.8009 - val_loss: 0.4677 - val_acc: 0.8161\n",
      "Epoch 5/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8008Epoch 00005: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 481us/step - loss: 0.5049 - acc: 0.8007 - val_loss: 0.4708 - val_acc: 0.7922\n",
      "Epoch 6/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.5009 - acc: 0.8029Epoch 00006: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.5010 - acc: 0.8027 - val_loss: 0.4667 - val_acc: 0.8117\n",
      "Epoch 7/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8057Epoch 00007: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 474us/step - loss: 0.4915 - acc: 0.8062 - val_loss: 0.4565 - val_acc: 0.8132\n",
      "Epoch 8/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4914 - acc: 0.8044Epoch 00008: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 478us/step - loss: 0.4908 - acc: 0.8047 - val_loss: 0.4657 - val_acc: 0.8072\n",
      "Epoch 9/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4828 - acc: 0.8050Epoch 00009: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 477us/step - loss: 0.4841 - acc: 0.8043 - val_loss: 0.4492 - val_acc: 0.8161\n",
      "Epoch 10/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8080Epoch 00010: val_acc improved from 0.81614 to 0.82362, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 493us/step - loss: 0.4755 - acc: 0.8080 - val_loss: 0.4610 - val_acc: 0.8236\n",
      "Epoch 11/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8103Epoch 00011: val_acc improved from 0.82362 to 0.82661, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 489us/step - loss: 0.4723 - acc: 0.8103 - val_loss: 0.4533 - val_acc: 0.8266\n",
      "Epoch 12/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8113Epoch 00012: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.4641 - acc: 0.8117 - val_loss: 0.4552 - val_acc: 0.8132\n",
      "Epoch 13/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8125Epoch 00013: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 475us/step - loss: 0.4595 - acc: 0.8124 - val_loss: 0.4421 - val_acc: 0.8221\n",
      "Epoch 14/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8161Epoch 00014: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 476us/step - loss: 0.4528 - acc: 0.8159 - val_loss: 0.4441 - val_acc: 0.8161\n",
      "Epoch 15/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8198Epoch 00015: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 480us/step - loss: 0.4451 - acc: 0.8198 - val_loss: 0.4393 - val_acc: 0.8206\n",
      "Epoch 16/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8238Epoch 00016: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.4316 - acc: 0.8236 - val_loss: 0.4448 - val_acc: 0.8206\n",
      "Epoch 17/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4246 - acc: 0.8263Epoch 00017: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 479us/step - loss: 0.4242 - acc: 0.8264 - val_loss: 0.4469 - val_acc: 0.8161\n",
      "Epoch 18/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8308Epoch 00018: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 479us/step - loss: 0.4175 - acc: 0.8307 - val_loss: 0.4537 - val_acc: 0.8236\n",
      "Epoch 19/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8322Epoch 00019: val_acc improved from 0.82661 to 0.82960, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 496us/step - loss: 0.4042 - acc: 0.8325 - val_loss: 0.4603 - val_acc: 0.8296\n",
      "Epoch 20/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8402Epoch 00020: val_acc improved from 0.82960 to 0.82960, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 485us/step - loss: 0.3943 - acc: 0.8399 - val_loss: 0.4355 - val_acc: 0.8296\n",
      "Epoch 21/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8485Epoch 00021: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.3801 - acc: 0.8486 - val_loss: 0.4627 - val_acc: 0.8266\n",
      "Epoch 22/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8484Epoch 00022: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 479us/step - loss: 0.3716 - acc: 0.8485 - val_loss: 0.4843 - val_acc: 0.8206\n",
      "Epoch 23/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8606Epoch 00023: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 476us/step - loss: 0.3508 - acc: 0.8605 - val_loss: 0.4745 - val_acc: 0.8236\n",
      "Epoch 24/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.3356 - acc: 0.8673Epoch 00024: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 478us/step - loss: 0.3359 - acc: 0.8670 - val_loss: 0.5185 - val_acc: 0.8161\n",
      "Epoch 25/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.8785Epoch 00025: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 479us/step - loss: 0.3132 - acc: 0.8781 - val_loss: 0.5399 - val_acc: 0.8072\n",
      "Epoch 26/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.8836Epoch 00026: val_acc improved from 0.82960 to 0.83408, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 491us/step - loss: 0.3021 - acc: 0.8830 - val_loss: 0.5345 - val_acc: 0.8341\n",
      "Epoch 27/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.8910Epoch 00027: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.2816 - acc: 0.8908 - val_loss: 0.5677 - val_acc: 0.8132\n",
      "Epoch 28/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.8957Epoch 00028: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 478us/step - loss: 0.2646 - acc: 0.8958 - val_loss: 0.5827 - val_acc: 0.8206\n",
      "Epoch 29/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9117Epoch 00029: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 475us/step - loss: 0.2401 - acc: 0.9116 - val_loss: 0.5562 - val_acc: 0.8117\n",
      "Epoch 30/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2270 - acc: 0.9136Epoch 00030: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 483us/step - loss: 0.2270 - acc: 0.9134 - val_loss: 0.5962 - val_acc: 0.7967\n",
      "Epoch 31/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9236Epoch 00031: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 476us/step - loss: 0.2075 - acc: 0.9233 - val_loss: 0.6013 - val_acc: 0.8072\n",
      "Epoch 32/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9322Epoch 00032: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 476us/step - loss: 0.1869 - acc: 0.9323 - val_loss: 0.6613 - val_acc: 0.7937\n",
      "Epoch 33/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9380Epoch 00033: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 488us/step - loss: 0.1737 - acc: 0.9378 - val_loss: 0.7164 - val_acc: 0.8027\n",
      "Epoch 34/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9381Epoch 00034: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.1674 - acc: 0.9382 - val_loss: 0.6821 - val_acc: 0.7862\n",
      "Epoch 35/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9471Epoch 00035: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 488us/step - loss: 0.1494 - acc: 0.9471 - val_loss: 0.7358 - val_acc: 0.8042\n",
      "Epoch 36/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9499Epoch 00036: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 485us/step - loss: 0.1414 - acc: 0.9499 - val_loss: 0.7201 - val_acc: 0.8102\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "lstm_input = Input(shape=(max(train_df.slidesCount), 96,))\n",
    "lstm_model = LSTM(HIDDEN_SIZE, recurrent_dropout=0.05, dropout=0.05)(lstm_input)\n",
    "lstm_first_dense = Dense(int(HIDDEN_SIZE/4), activation='elu')(lstm_model)\n",
    "# lstm_first_dropout = Dropout(0.1)(lstm_first_dense)\n",
    "lstm_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_first_dense)\n",
    "lstm_second_dense = Dense(int(HIDDEN_SIZE/5), activation='elu')(lstm_first_bn)\n",
    "lstm_second_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_second_dense)\n",
    "lstm_third_dense = Dense(int(HIDDEN_SIZE/6), activation='elu')(lstm_second_bn)\n",
    "lstm_third_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_third_dense)\n",
    "lstm_classify_dense = Dense(3, activation='softmax')(lstm_third_bn)\n",
    "extra_input = Input(shape=(len(all_features),))\n",
    "# extra_dense = Dense(len(all_features), activation='linear')(extra_input)\n",
    "merged = concatenate([lstm_classify_dense, extra_input])\n",
    "model_first_dense = Dense(7, activation='elu')(merged)\n",
    "moden_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(model_first_dense)\n",
    "model_dense = Dense(3, activation='softmax')(moden_first_bn)\n",
    "model = Model(inputs=[lstm_input, extra_input], outputs=model_dense)\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit([ X_lstm_train, df_train],  y_lstm_train, validation_data=([X_lstm_valid, df_valid], y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12696 samples, validate on 669 samples\n",
      "Epoch 1/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.8412 - acc: 0.6751Epoch 00001: val_acc improved from -inf to 0.80419, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 15s 1ms/step - loss: 0.8401 - acc: 0.6755 - val_loss: 0.5483 - val_acc: 0.8042\n",
      "Epoch 2/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.5507 - acc: 0.7916Epoch 00002: val_acc improved from 0.80419 to 0.81315, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 505us/step - loss: 0.5501 - acc: 0.7917 - val_loss: 0.4936 - val_acc: 0.8132\n",
      "Epoch 3/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.5178 - acc: 0.7976Epoch 00003: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 478us/step - loss: 0.5178 - acc: 0.7977 - val_loss: 0.4644 - val_acc: 0.8072\n",
      "Epoch 4/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.7998Epoch 00004: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 483us/step - loss: 0.5093 - acc: 0.8001 - val_loss: 0.4567 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.5015 - acc: 0.7986Epoch 00005: val_acc improved from 0.81315 to 0.81913, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 491us/step - loss: 0.5014 - acc: 0.7986 - val_loss: 0.4602 - val_acc: 0.8191\n",
      "Epoch 6/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.7997Epoch 00006: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.4954 - acc: 0.7999 - val_loss: 0.4438 - val_acc: 0.8176\n",
      "Epoch 7/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.8000Epoch 00007: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.4924 - acc: 0.8000 - val_loss: 0.4435 - val_acc: 0.8176\n",
      "Epoch 8/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4884 - acc: 0.8014Epoch 00008: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 474us/step - loss: 0.4882 - acc: 0.8013 - val_loss: 0.4389 - val_acc: 0.8132\n",
      "Epoch 9/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8042Epoch 00009: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 481us/step - loss: 0.4798 - acc: 0.8051 - val_loss: 0.4356 - val_acc: 0.8176\n",
      "Epoch 10/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4773 - acc: 0.8059Epoch 00010: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 480us/step - loss: 0.4781 - acc: 0.8058 - val_loss: 0.4479 - val_acc: 0.8132\n",
      "Epoch 11/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8114Epoch 00011: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.4701 - acc: 0.8116 - val_loss: 0.4432 - val_acc: 0.8042\n",
      "Epoch 12/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.8138Epoch 00012: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.4573 - acc: 0.8136 - val_loss: 0.4377 - val_acc: 0.8146\n",
      "Epoch 13/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8141Epoch 00013: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 480us/step - loss: 0.4570 - acc: 0.8140 - val_loss: 0.4482 - val_acc: 0.8117\n",
      "Epoch 14/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8143Epoch 00014: val_acc improved from 0.81913 to 0.82960, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 492us/step - loss: 0.4480 - acc: 0.8144 - val_loss: 0.4341 - val_acc: 0.8296\n",
      "Epoch 15/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.8181Epoch 00015: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 479us/step - loss: 0.4398 - acc: 0.8180 - val_loss: 0.4473 - val_acc: 0.8146\n",
      "Epoch 16/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8257Epoch 00016: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 477us/step - loss: 0.4335 - acc: 0.8255 - val_loss: 0.4663 - val_acc: 0.8087\n",
      "Epoch 17/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8278Epoch 00017: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 486us/step - loss: 0.4231 - acc: 0.8275 - val_loss: 0.4344 - val_acc: 0.8236\n",
      "Epoch 18/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.4096 - acc: 0.8326Epoch 00018: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 476us/step - loss: 0.4088 - acc: 0.8330 - val_loss: 0.4460 - val_acc: 0.8266\n",
      "Epoch 19/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8376Epoch 00019: val_acc improved from 0.82960 to 0.83109, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 493us/step - loss: 0.3989 - acc: 0.8381 - val_loss: 0.4409 - val_acc: 0.8311\n",
      "Epoch 20/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8445Epoch 00020: val_acc improved from 0.83109 to 0.83408, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 494us/step - loss: 0.3858 - acc: 0.8444 - val_loss: 0.4577 - val_acc: 0.8341\n",
      "Epoch 21/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8522Epoch 00021: val_acc improved from 0.83408 to 0.84305, saving model to ./slides_lstm.model\n",
      "12696/12696 [==============================] - 6s 496us/step - loss: 0.3675 - acc: 0.8521 - val_loss: 0.4273 - val_acc: 0.8430\n",
      "Epoch 22/100\n",
      "12650/12696 [============================>.] - ETA: 0s - loss: 0.3572 - acc: 0.8569Epoch 00022: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.3567 - acc: 0.8572 - val_loss: 0.4562 - val_acc: 0.8266\n",
      "Epoch 23/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8652Epoch 00023: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 482us/step - loss: 0.3357 - acc: 0.8648 - val_loss: 0.4485 - val_acc: 0.8386\n",
      "Epoch 24/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8766Epoch 00024: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 485us/step - loss: 0.3160 - acc: 0.8766 - val_loss: 0.4948 - val_acc: 0.8206\n",
      "Epoch 25/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.3012 - acc: 0.8808Epoch 00025: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 487us/step - loss: 0.3016 - acc: 0.8808 - val_loss: 0.4993 - val_acc: 0.8326\n",
      "Epoch 26/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.8892Epoch 00026: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.2835 - acc: 0.8891 - val_loss: 0.4564 - val_acc: 0.8401\n",
      "Epoch 27/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.8997Epoch 00027: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 480us/step - loss: 0.2600 - acc: 0.8997 - val_loss: 0.5233 - val_acc: 0.8221\n",
      "Epoch 28/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9112Epoch 00028: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 473us/step - loss: 0.2423 - acc: 0.9113 - val_loss: 0.5518 - val_acc: 0.8206\n",
      "Epoch 29/100\n",
      "12550/12696 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9196Epoch 00029: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 484us/step - loss: 0.2215 - acc: 0.9198 - val_loss: 0.5465 - val_acc: 0.8176\n",
      "Epoch 30/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9244Epoch 00030: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 481us/step - loss: 0.2074 - acc: 0.9244 - val_loss: 0.5816 - val_acc: 0.8117\n",
      "Epoch 31/100\n",
      "12600/12696 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9284Epoch 00031: val_acc did not improve\n",
      "12696/12696 [==============================] - 6s 481us/step - loss: 0.1902 - acc: 0.9285 - val_loss: 0.5516 - val_acc: 0.8221\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "lstm_input = Input(shape=(max(train_df.slidesCount), 96,))\n",
    "lstm_model = LSTM(HIDDEN_SIZE, recurrent_dropout=0.05, dropout=0.1)(lstm_input)\n",
    "lstm_first_dense = Dense(int(HIDDEN_SIZE/4), activation='elu')(lstm_model)\n",
    "# lstm_first_dropout = Dropout(0.1)(lstm_first_dense)\n",
    "lstm_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_first_dense)\n",
    "lstm_second_dense = Dense(int(HIDDEN_SIZE/5), activation='elu')(lstm_first_bn)\n",
    "lstm_second_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_second_dense)\n",
    "lstm_third_dense = Dense(int(HIDDEN_SIZE/6), activation='elu')(lstm_second_bn)\n",
    "lstm_third_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(lstm_third_dense)\n",
    "lstm_classify_dense = Dense(3, activation='softmax')(lstm_third_bn)\n",
    "extra_input = Input(shape=(len(all_features),))\n",
    "# extra_dense = Dense(len(all_features), activation='linear')(extra_input)\n",
    "merged = concatenate([lstm_classify_dense, extra_input])\n",
    "model_first_dense = Dense(7, activation='elu')(merged)\n",
    "moden_first_bn = BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)(model_first_dense)\n",
    "model_dense = Dense(3, activation='softmax')(moden_first_bn)\n",
    "model = Model(inputs=[lstm_input, extra_input], outputs=model_dense)\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit([ X_lstm_train, df_train],  y_lstm_train, validation_data=([X_lstm_valid, df_valid], y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3)\n",
      "(None, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  \n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(momentum=0.9, weights=None, epsilon=1e-06)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`Concatenate` layer should be called on a list of inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-367cb3e85f6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# model = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# model.add(Merge([model_lstm, extra], mode='concat', concat_axis=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# print(model.output_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diploma/cv/ipython/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    487\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/diploma/cv/ipython/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diploma/cv/ipython/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# Used purely for shape validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             raise ValueError('`Concatenate` layer should be called '\n\u001b[0m\u001b[1;32m    329\u001b[0m                              'on a list of inputs')\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `Concatenate` layer should be called on a list of inputs"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "HIDDEN_SIZE = 200\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', input_shape=(max(train_df.slidesCount), 96), activation='elu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(recurrent.LSTM(HIDDEN_SIZE, input_shape=(max(train_df.slidesCount), 96), recurrent_dropout=0.05, dropout=0.05))\n",
    "model.add( Dense( int(HIDDEN_SIZE/4), activation='elu' ))\n",
    "# model.add( Dropout(0.1) )\n",
    "model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "model.add( Dense( int(HIDDEN_SIZE/5), activation='elu' ))\n",
    "model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "model.add( Dropout(0.1) )\n",
    "model.add( Dense( int(HIDDEN_SIZE/6), activation='elu' ))\n",
    "model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "# model.add( Dropout(0.1) )\n",
    "model.add( Dense( 3, activation='softmax' ) )\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'] )\n",
    "\n",
    "model_checkpoint = ModelCheckpoint( os.path.join('./','slides_lstm.model'), monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping( monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit( X_lstm_train, y_lstm_train, validation_data=(X_lstm_valid, y_lstm_valid), \n",
    "                    batch_size=50, epochs=100, callbacks=[model_checkpoint, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('./','slides_lstm.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict([X_lstm_valid, df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84304932735426008"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.50      0.55        48\n",
      "          2       0.67      0.48      0.56        90\n",
      "          3       0.88      0.94      0.91       531\n",
      "\n",
      "avg / total       0.83      0.84      0.83       669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/pgulyaev/diploma/cv/ipython/lib/python3.5/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-84c84fbc034e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert one-hot to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_lstm_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "Y_valid = np.argmax(y_valid, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes([X_lstm_valid, df_valid])\n",
    "print(classification_report(Y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('./','slides_lstm.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_lstm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('probs.npy', probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81763826606875933"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.38      0.46        48\n",
      "          2       0.70      0.21      0.32        90\n",
      "          3       0.83      0.96      0.89       531\n",
      "\n",
      "avg / total       0.80      0.82      0.79       669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_lstm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808526551982049"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.47      0.48        96\n",
      "          2       0.40      0.25      0.31       179\n",
      "          3       0.84      0.90      0.87      1062\n",
      "\n",
      "avg / total       0.76      0.78      0.77      1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_lstm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for prob in probs:\n",
    "    y_pred.append(np.argmax(prob)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.42      0.47        96\n",
      "          2       0.41      0.42      0.42       179\n",
      "          3       0.85      0.87      0.86      1062\n",
      "\n",
      "avg / total       0.77      0.78      0.77      1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без дополнительных ок-ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.57      0.63       102\n",
      "          2       0.56      0.44      0.49       179\n",
      "          3       0.78      0.86      0.81       558\n",
      "\n",
      "avg / total       0.72      0.73      0.72       839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.071380471380471378, 2: 0.13408155630377852, 3: 0.79453797231575007}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts/sum(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
